{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-13T18:06:43.051488Z",
     "iopub.status.busy": "2025-07-13T18:06:43.051192Z",
     "iopub.status.idle": "2025-07-13T18:06:43.401291Z",
     "shell.execute_reply": "2025-07-13T18:06:43.400619Z",
     "shell.execute_reply.started": "2025-07-13T18:06:43.051463Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/HPV/clean_HPV_texts_phi3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/HPV/clean_HPV_texts_Phi_fear.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/HPV/clean_HPV_texts_phi3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/HPV/clean_HPV_texts_phi_religious_conspiracy.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/COVID-19/clean_COVID-19_texts_phi3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/COVID-19/clean_COVID-19_texts_phi3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/COVID-19/clean_COVID-19_texts__phi3_fear.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/COVID-19/clean_COVID-19_texts_phi_religious_conspiracy (2).csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/INFLUENZA/clean_Influenza_texts_phi_fear_monger.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/INFLUENZA/clean_Influenza_texts_phi3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/INFLUENZA/clean_Influenza_texts_phi3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/INFLUENZA/clean_Influenza_texts_phi_religious_conspiracy.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_fear mongerer.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_fear mongerer.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_fear mongerer.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_fear mongerer.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_fear mongerer.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_fear mongerer.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/HPV/clean_HPV_texts_llama_religious.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/HPV/clean_HPV_texts_llama3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/HPV/clean_HPV_texts_llama_fear_monger.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/HPV/clean_HPV_texts_llama3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/COVID-19/clean_COVID-19_texts_llama_religious.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/COVID-19/clean_COVID-19_texts_llama3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/COVID-19/clean_COVID-19_texts_llama_fear_monger.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/COVID-19/clean_COVID-19_texts_llama3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/INFLUENZA/clean_Influenza_texts_llama_reilgious.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/INFLUENZA/clean_Influenza_texts_llama3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/INFLUENZA/clean_Influenza_texts_llama3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/INFLUENZA/clean_Influenza_texts_llama_fear_monger.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_fear.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_religious.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_fear.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_religious.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_religious.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_fear.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_Misinformation spreader.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T17:21:59.664064Z",
     "iopub.status.busy": "2025-07-13T17:21:59.663621Z",
     "iopub.status.idle": "2025-07-13T17:22:06.853780Z",
     "shell.execute_reply": "2025-07-13T17:22:06.852940Z",
     "shell.execute_reply.started": "2025-07-13T17:21:59.664041Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate datasets evaluate -q\n",
    "!pip install huggingface_hub -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misinformation Spreader\n",
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T07:45:20.423638Z",
     "iopub.status.busy": "2025-07-14T07:45:20.423425Z",
     "iopub.status.idle": "2025-07-14T07:50:33.441591Z",
     "shell.execute_reply": "2025-07-14T07:50:33.440647Z",
     "shell.execute_reply.started": "2025-07-14T07:45:20.423610Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe256349666431ea75c0c5b0f4fbe6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/137k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c875a11f441e4247aba1cbaa9a30c1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc2457bb4ae468eb0398b28d3edbd77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6d6d7bf47a4065b1c03d65def08a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f76d33161b84e108ec550e919a5b4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 07:45:42.139260: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752479142.318632      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752479142.374396      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa2f3d38fe44551b601dac8e04c71e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4671d132e87432bad529309b58e2ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0551f73768584f81bb7569951aefd1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0646f14402e144888282f868ce504ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c538679142b43c799449b963affbf82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e58b908bae4b00ab84ae4d1f94b522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0050fe55517e45a8838e8deea5b26e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_mistral_Misinformation spreader.csv: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Classifying clean_HPV_texts_mistral_Misinformation spreader.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_Influenza_texts_mistral_Misinformation spreader.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.4700\n",
      "  ✅ Precision: 0.2350\n",
      "  ✅ Recall:    0.5000\n",
      "  ✅ F1 Score:  0.3197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Login to Hugging Face ===\n",
    "login(\"\")  # <-- Replace with your real Hugging Face token\n",
    "\n",
    "# === Load Mistral-7B-v0.3 ===\n",
    "model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_Misinformation spreader.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional cap for faster processing\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anti-Vacciner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T07:54:05.043650Z",
     "iopub.status.busy": "2025-07-14T07:54:05.042987Z",
     "iopub.status.idle": "2025-07-14T07:57:53.185136Z",
     "shell.execute_reply": "2025-07-14T07:57:53.184323Z",
     "shell.execute_reply.started": "2025-07-14T07:54:05.043621Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1ae1de3d544a74826f7cf12e6d8bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_mistral_Anti-Vacciner.csv: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Classifying clean_HPV_texts_mistral_Anti-Vacciner.csv: 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]\n",
      "Classifying clean_Influenza_texts_mistral_Anti-Vacciner.csv: 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.4800\n",
      "  ✅ Precision: 0.2400\n",
      "  ✅ Recall:    0.5000\n",
      "  ✅ F1 Score:  0.3243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Login to Hugging Face ===\n",
    "login(\"\")  # <-- Replace with your real Hugging Face token\n",
    "\n",
    "# === Load Mistral-7B-v0.3 ===\n",
    "model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_Anti-Vacciner.csv'\n",
    "]\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional cap for faster processing\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Religious Conspiracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T07:59:56.291891Z",
     "iopub.status.busy": "2025-07-14T07:59:56.291596Z",
     "iopub.status.idle": "2025-07-14T08:03:30.488654Z",
     "shell.execute_reply": "2025-07-14T08:03:30.487903Z",
     "shell.execute_reply.started": "2025-07-14T07:59:56.291869Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03402f5bd31c46efb5016f72d681fa45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_mistral_religious.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_HPV_texts_mistral_religious.csv: 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]\n",
      "Classifying clean_Influenza_texts_mistral_religious.csv: 100%|██████████| 100/100 [01:05<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.5467\n",
      "  ✅ Precision: 0.2733\n",
      "  ✅ Recall:    0.5000\n",
      "  ✅ F1 Score:  0.3534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Login to Hugging Face ===\n",
    "login(\"\")  # <-- Replace with your real Hugging Face token\n",
    "\n",
    "# === Load Mistral-7B-v0.3 ===\n",
    "model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_religious.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_religious.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_religious.csv'\n",
    "]\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional cap for faster processing\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fear Monger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T08:04:39.615467Z",
     "iopub.status.busy": "2025-07-14T08:04:39.614973Z",
     "iopub.status.idle": "2025-07-14T08:08:13.455610Z",
     "shell.execute_reply": "2025-07-14T08:08:13.454692Z",
     "shell.execute_reply.started": "2025-07-14T08:04:39.615440Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45a8bf73e5144a88243d91b1c1047aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_mistral_fear.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_HPV_texts_mistral_fear.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_Influenza_texts_mistral_fear.csv: 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.4933\n",
      "  ✅ Precision: 0.2467\n",
      "  ✅ Recall:    0.5000\n",
      "  ✅ F1 Score:  0.3304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Login to Hugging Face ===\n",
    "login(\"\")  # <-- Replace with your real Hugging Face token\n",
    "\n",
    "# === Load Mistral-7B-v0.3 ===\n",
    "model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_fear.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_fear.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_fear.csv'\n",
    "]\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional cap for faster processing\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T08:41:53.499104Z",
     "iopub.status.busy": "2025-07-14T08:41:53.498678Z",
     "iopub.status.idle": "2025-07-14T08:46:36.053517Z",
     "shell.execute_reply": "2025-07-14T08:46:36.052852Z",
     "shell.execute_reply.started": "2025-07-14T08:41:53.499081Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8413ac096bd497fafc863d963035108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_mistral_Anti-Vacciner.csv: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Classifying clean_COVID-19_texts_mistral_Misinformation spreader.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_COVID-19_texts_mistral_fear.csv: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Classifying clean_COVID-19_texts_mistral_fear.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.4925\n",
      "  ✅ Precision: 0.2462\n",
      "  ✅ Recall:    0.5000\n",
      "  ✅ F1 Score:  0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Login to Hugging Face ===\n",
    "login(\"\")  # <-- Replace with your real Hugging Face token\n",
    "\n",
    "# === Load Mistral-7B-v0.3 ===\n",
    "model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_fear.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_fear.csv'\n",
    "]\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional cap for faster processing\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T08:46:52.137277Z",
     "iopub.status.busy": "2025-07-14T08:46:52.136893Z",
     "iopub.status.idle": "2025-07-14T08:51:32.881601Z",
     "shell.execute_reply": "2025-07-14T08:51:32.880768Z",
     "shell.execute_reply.started": "2025-07-14T08:46:52.137251Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d905263efa842dd98156d82427ad2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_mistral_religious.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_Influenza_texts_mistral_fear.csv: 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]\n",
      "Classifying clean_Influenza_texts_mistral_Misinformation spreader.csv: 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]\n",
      "Classifying clean_Influenza_texts_mistral_Anti-Vacciner.csv: 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.4750\n",
      "  ✅ Precision: 0.2375\n",
      "  ✅ Recall:    0.5000\n",
      "  ✅ F1 Score:  0.3220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Login to Hugging Face ===\n",
    "login(\"\")  # <-- Replace with your real Hugging Face token\n",
    "\n",
    "# === Load Mistral-7B-v0.3 ===\n",
    "model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_religious.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_fear.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_Anti-Vacciner.csv'\n",
    "]\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional cap for faster processing\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T08:51:38.912854Z",
     "iopub.status.busy": "2025-07-14T08:51:38.912567Z",
     "iopub.status.idle": "2025-07-14T08:56:23.572938Z",
     "shell.execute_reply": "2025-07-14T08:56:23.572211Z",
     "shell.execute_reply.started": "2025-07-14T08:51:38.912833Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5ade0aff9c46ab84b2ee8d07762f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_HPV_texts_mistral_religious.csv: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Classifying clean_HPV_texts_mistral_fear.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_HPV_texts_mistral_Misinformation spreader.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_HPV_texts_mistral_Anti-Vacciner.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.4550\n",
      "  ✅ Precision: 0.2275\n",
      "  ✅ Recall:    0.5000\n",
      "  ✅ F1 Score:  0.3127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Login to Hugging Face ===\n",
    "login(\"\")  # <-- Replace with your real Hugging Face token\n",
    "\n",
    "# === Load Mistral-7B-v0.3 ===\n",
    "model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_religious.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_fear.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_Anti-Vacciner.csv'\n",
    "]\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional cap for faster processing\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T08:16:00.290992Z",
     "iopub.status.busy": "2025-07-14T08:16:00.290166Z",
     "iopub.status.idle": "2025-07-14T08:29:30.756243Z",
     "shell.execute_reply": "2025-07-14T08:29:30.755458Z",
     "shell.execute_reply.started": "2025-07-14T08:16:00.290958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819b487adcea4ac491f6997037c60c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_mistral_fear.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_HPV_texts_mistral_fear.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_Influenza_texts_mistral_fear.csv: 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]\n",
      "Classifying clean_COVID-19_texts_mistral_religious.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_HPV_texts_mistral_religious.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_Influenza_texts_mistral_religious.csv: 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]\n",
      "Classifying clean_COVID-19_texts_mistral_Anti-Vacciner.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_HPV_texts_mistral_Anti-Vacciner.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_Influenza_texts_mistral_Anti-Vacciner.csv: 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]\n",
      "Classifying clean_COVID-19_texts_mistral_Misinformation spreader.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_HPV_texts_mistral_Misinformation spreader.csv: 100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n",
      "Classifying clean_Influenza_texts_mistral_Misinformation spreader.csv: 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.4967\n",
      "  ✅ Precision: 0.2483\n",
      "  ✅ Recall:    0.5000\n",
      "  ✅ F1 Score:  0.3318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Login to Hugging Face ===\n",
    "login(\"\")  # <-- Replace with your real Hugging Face token\n",
    "\n",
    "# === Load Mistral-7B-v0.3 ===\n",
    "model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_fear.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_fear.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_fear.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_religious.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_religious.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_religious.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_Misinformation spreader.csv'\n",
    "]\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional cap for faster processing\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7859405,
     "sourceId": 12459014,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
