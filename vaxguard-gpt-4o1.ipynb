{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!pip install transformers accelerate datasets evaluate -q\n",
    "#!pip install huggingface_hub -q\n",
    "!pip install --upgrade openai\n",
    "!pip install --upgrade transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misinformation Spreader\n",
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T10:20:25.794555Z",
     "iopub.status.busy": "2025-07-15T10:20:25.794021Z",
     "iopub.status.idle": "2025-07-15T10:22:56.012267Z",
     "shell.execute_reply": "2025-07-15T10:22:56.011565Z",
     "shell.execute_reply.started": "2025-07-15T10:20:25.794524Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_GPT-4o_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:48<00:00,  2.08it/s]\n",
      "Classifying clean_HPV_texts_GPT-4o_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.87it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-4o_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:48<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.8833\n",
      "  âœ… Precision: 0.6004\n",
      "  âœ… Recall:    0.6667\n",
      "  âœ… F1 Score:  0.6299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # âœ… Updated to GPT-4o\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_Misinformation spreader.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  âœ… Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  âœ… Precision: {overall_prec:.4f}\")\n",
    "print(f\"  âœ… Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  âœ… F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Religious Conspiracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T10:24:14.286824Z",
     "iopub.status.busy": "2025-07-15T10:24:14.286059Z",
     "iopub.status.idle": "2025-07-15T10:27:14.860516Z",
     "shell.execute_reply": "2025-07-15T10:27:14.859786Z",
     "shell.execute_reply.started": "2025-07-15T10:24:14.286794Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_GPT-4o_religious Conspiracy theorist.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:50<00:00,  1.96it/s]\n",
      "Classifying clean_HPV_texts_GPT-4o_religious Conspiracy theorist.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:48<00:00,  2.06it/s]\n",
      "Classifying clean_Influenza_texts_GPT-4o_religious Conspiracy theorist.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:20<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.8833\n",
      "  âœ… Precision: 0.5928\n",
      "  âœ… Recall:    0.6667\n",
      "  âœ… F1 Score:  0.6251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # âœ… Updated to GPT-4o\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_religious Conspiracy theorist.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  âœ… Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  âœ… Precision: {overall_prec:.4f}\")\n",
    "print(f\"  âœ… Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  âœ… F1 Score:  {overall_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fear Monger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T10:27:58.359886Z",
     "iopub.status.busy": "2025-07-15T10:27:58.359604Z",
     "iopub.status.idle": "2025-07-15T10:30:33.740850Z",
     "shell.execute_reply": "2025-07-15T10:30:33.740098Z",
     "shell.execute_reply.started": "2025-07-15T10:27:58.359862Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_GPT-4o_fear mongerer.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:51<00:00,  1.93it/s]\n",
      "Classifying clean_HPV_texts_GPT-4o_fear mongerer.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:44<00:00,  2.23it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-4o_fear mongerer.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:58<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.9067\n",
      "  âœ… Precision: 0.6049\n",
      "  âœ… Recall:    0.6667\n",
      "  âœ… F1 Score:  0.6326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # âœ… Updated to GPT-4o\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_fear mongerer.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  âœ… Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  âœ… Precision: {overall_prec:.4f}\")\n",
    "print(f\"  âœ… Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  âœ… F1 Score:  {overall_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anti vacciner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T10:32:23.671642Z",
     "iopub.status.busy": "2025-07-15T10:32:23.670872Z",
     "iopub.status.idle": "2025-07-15T10:34:55.409098Z",
     "shell.execute_reply": "2025-07-15T10:34:55.408356Z",
     "shell.execute_reply.started": "2025-07-15T10:32:23.671612Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_GPT-4o_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.01it/s]\n",
      "Classifying clean_HPV_texts_GPT-4o_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:46<00:00,  2.15it/s]\n",
      "Classifying clean_Influenza_texts_GPT-4o_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:55<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.8800\n",
      "  âœ… Precision: 0.5944\n",
      "  âœ… Recall:    0.6667\n",
      "  âœ… F1 Score:  0.6261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # âœ… Updated to GPT-4o\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_Anti-Vacciner.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  âœ… Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  âœ… Precision: {overall_prec:.4f}\")\n",
    "print(f\"  âœ… Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  âœ… F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVID 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T10:35:12.620017Z",
     "iopub.status.busy": "2025-07-15T10:35:12.619429Z",
     "iopub.status.idle": "2025-07-15T10:38:29.605493Z",
     "shell.execute_reply": "2025-07-15T10:38:29.604775Z",
     "shell.execute_reply.started": "2025-07-15T10:35:12.619993Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_GPT-4o_religious Conspiracy theorist.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:42<00:00,  2.36it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-4o_fear mongerer.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:47<00:00,  2.11it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-4o_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:00<00:00,  1.65it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-4o_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:46<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.6050\n",
      "  âœ… Precision: 0.4772\n",
      "  âœ… Recall:    0.6667\n",
      "  âœ… F1 Score:  0.5343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # âœ… Updated to GPT-4o\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_Anti-Vacciner.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  âœ… Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  âœ… Precision: {overall_prec:.4f}\")\n",
    "print(f\"  âœ… Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  âœ… F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T10:38:30.340507Z",
     "iopub.status.busy": "2025-07-15T10:38:30.339764Z",
     "iopub.status.idle": "2025-07-15T10:42:25.226884Z",
     "shell.execute_reply": "2025-07-15T10:42:25.226049Z",
     "shell.execute_reply.started": "2025-07-15T10:38:30.340481Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_HPV_texts_GPT-4o_religious Conspiracy theorist.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:53<00:00,  1.86it/s]\n",
      "Classifying clean_HPV_texts_GPT-4o_fear mongerer.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:04<00:00,  1.54it/s]\n",
      "Classifying clean_HPV_texts_GPT-4o_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:07<00:00,  1.49it/s]\n",
      "Classifying clean_HPV_texts_GPT-4o_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  1.0000\n",
      "  âœ… Precision: 1.0000\n",
      "  âœ… Recall:    1.0000\n",
      "  âœ… F1 Score:  1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # âœ… Updated to GPT-4o\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_Anti-Vacciner.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  âœ… Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  âœ… Precision: {overall_prec:.4f}\")\n",
    "print(f\"  âœ… Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  âœ… F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFLUENZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T10:43:28.461955Z",
     "iopub.status.busy": "2025-07-15T10:43:28.461356Z",
     "iopub.status.idle": "2025-07-15T10:48:04.630977Z",
     "shell.execute_reply": "2025-07-15T10:48:04.630320Z",
     "shell.execute_reply.started": "2025-07-15T10:43:28.461932Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_GPT-4o_religious Conspiracy theorist.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:22<00:00,  1.21it/s]\n",
      "Classifying clean_Influenza_texts_GPT-4o_fear mongerer.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:31<00:00,  1.09it/s]\n",
      "Classifying clean_Influenza_texts_GPT-4o_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:50<00:00,  1.97it/s]\n",
      "Classifying clean_Influenza_texts_GPT-4o_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:50<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  1.0000\n",
      "  âœ… Precision: 1.0000\n",
      "  âœ… Recall:    1.0000\n",
      "  âœ… F1 Score:  1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # âœ… Updated to GPT-4o\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_Misinformation spreader.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  âœ… Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  âœ… Precision: {overall_prec:.4f}\")\n",
    "print(f\"  âœ… Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  âœ… F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T10:48:04.632817Z",
     "iopub.status.busy": "2025-07-15T10:48:04.632189Z",
     "iopub.status.idle": "2025-07-15T11:00:42.079800Z",
     "shell.execute_reply": "2025-07-15T11:00:42.079108Z",
     "shell.execute_reply.started": "2025-07-15T10:48:04.632795Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_GPT-4o_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:50<00:00,  1.97it/s]\n",
      "Classifying clean_HPV_texts_GPT-4o_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:03<00:00,  1.57it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-4o_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [03:01<00:00,  1.81s/it]\n",
      "Classifying clean_COVID-19_texts_GPT-4o_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:48<00:00,  2.07it/s]\n",
      "Classifying clean_HPV_texts_GPT-4o_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:47<00:00,  2.12it/s]\n",
      "Classifying clean_Influenza_texts_GPT-4o_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:45<00:00,  2.18it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-4o_religious Conspiracy theorist.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:46<00:00,  2.15it/s]\n",
      "Classifying clean_HPV_texts_GPT-4o_religious Conspiracy theorist.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:03<00:00,  1.57it/s]\n",
      "Classifying clean_Influenza_texts_GPT-4o_religious Conspiracy theorist.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.01it/s]\n",
      "Classifying clean_Influenza_texts_GPT-4o_fear mongerer.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:49<00:00,  2.01it/s]\n",
      "Classifying clean_HPV_texts_GPT-4o_fear mongerer.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:54<00:00,  1.83it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-4o_fear mongerer.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:55<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.8883\n",
      "  âœ… Precision: 0.6011\n",
      "  âœ… Recall:    0.6667\n",
      "  âœ… F1 Score:  0.6303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # âœ… Updated to GPT-4o\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_fear mongerer.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  âœ… Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  âœ… Precision: {overall_prec:.4f}\")\n",
    "print(f\"  âœ… Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  âœ… F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7859405,
     "sourceId": 12459014,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
