{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-14T12:14:46.084720Z",
     "iopub.status.busy": "2025-07-14T12:14:46.084438Z",
     "iopub.status.idle": "2025-07-14T12:14:46.195417Z",
     "shell.execute_reply": "2025-07-14T12:14:46.194508Z",
     "shell.execute_reply.started": "2025-07-14T12:14:46.084674Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_phi3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_Phi_fear.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_phi3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_phi_religious_conspiracy.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts_phi3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts_phi3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts__phi3_fear.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts_phi_religious_conspiracy (2).csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi_fear_monger.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi_religious_conspiracy.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-4o/HPV/clean_HPV_texts_GPT-4o_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-4o/HPV/clean_HPV_texts_GPT-4o_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-4o/HPV/clean_HPV_texts_GPT-4o_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-4o/HPV/clean_HPV_texts_GPT-4o_fear mongerer.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_fear mongerer.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_fear mongerer.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_fear mongerer.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_fear mongerer.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_fear mongerer.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Llama 3/HPV/clean_HPV_texts_llama_religious.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Llama 3/HPV/clean_HPV_texts_llama3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Llama 3/HPV/clean_HPV_texts_llama_fear_monger.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Llama 3/HPV/clean_HPV_texts_llama3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Llama 3/COVID-19/clean_COVID-19_texts_llama_religious.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Llama 3/COVID-19/clean_COVID-19_texts_llama3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Llama 3/COVID-19/clean_COVID-19_texts_llama_fear_monger.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Llama 3/COVID-19/clean_COVID-19_texts_llama3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Llama 3/INFLUENZA/clean_Influenza_texts_llama_reilgious.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Llama 3/INFLUENZA/clean_Influenza_texts_llama3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Llama 3/INFLUENZA/clean_Influenza_texts_llama3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Llama 3/INFLUENZA/clean_Influenza_texts_llama_fear_monger.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Mistral/HPV/clean_HPV_texts_mistral_fear.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Mistral/HPV/clean_HPV_texts_mistral_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Mistral/HPV/clean_HPV_texts_mistral_religious.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Mistral/HPV/clean_HPV_texts_mistral_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Mistral/COVID-19/clean_COVID-19_texts_mistral_fear.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Mistral/COVID-19/clean_COVID-19_texts_mistral_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Mistral/COVID-19/clean_COVID-19_texts_mistral_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Mistral/COVID-19/clean_COVID-19_texts_mistral_religious.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Mistral/INFLUENZA/clean_Influenza_texts_mistral_religious.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Mistral/INFLUENZA/clean_Influenza_texts_mistral_fear.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Mistral/INFLUENZA/clean_Influenza_texts_mistral_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/Mistral/INFLUENZA/clean_Influenza_texts_mistral_Misinformation spreader.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T12:14:51.344337Z",
     "iopub.status.busy": "2025-07-14T12:14:51.343491Z",
     "iopub.status.idle": "2025-07-14T12:14:58.726125Z",
     "shell.execute_reply": "2025-07-14T12:14:58.725124Z",
     "shell.execute_reply.started": "2025-07-14T12:14:51.344287Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers accelerate datasets evaluate -q\n",
    "!pip install huggingface_hub -q\n",
    "!pip install --upgrade transformers --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misinformation Spreader\n",
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-14T12:15:10.539Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:22:14.514297Z",
     "iopub.status.busy": "2025-07-14T11:22:14.514014Z",
     "iopub.status.idle": "2025-07-14T11:25:30.609614Z",
     "shell.execute_reply": "2025-07-14T11:25:30.608871Z",
     "shell.execute_reply.started": "2025-07-14T11:22:14.514273Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 11:22:27.956665: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752492147.980889     143 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752492147.988545     143 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0632d29dd6ef4a77b6804c903af108f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_HPV_texts_phi3_Misinformation spreader.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_HPV_texts_phi3_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:58<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_COVID-19_texts_phi3_Misinformation spreader.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_phi3_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_Influenza_texts_phi3_Misinformation spreader.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_phi3_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.4667\n",
      "  âœ… Precision: 0.2333\n",
      "  âœ… Recall:    0.5000\n",
      "  âœ… F1 Score:  0.3182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# === Hugging Face Token ===\n",
    "login(\"\")  # Replace with your token\n",
    "\n",
    "# === Load Phi-3 Model ===\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt Formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            use_cache=False,  # â›” Fix for 'DynamicCache' bug\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === Your Files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_phi3_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts_phi3_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi3_Misinformation spreader.csv'\n",
    "]\n",
    "\n",
    "# === Evaluate Across Files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    print(f\"\\nðŸ” Loading file: {os.path.basename(file_path)}\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # ðŸ”„ Melt the dataframe so 'label' = column name, 'text' = value\n",
    "        df = pd.melt(df, var_name='label', value_name='text')\n",
    "        df.dropna(inplace=True)\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        df = df.head(100)  # Cap to 100 samples for speed\n",
    "        \n",
    "        y_true = df['label'].tolist()\n",
    "        y_pred = []\n",
    "\n",
    "        for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "            y_pred.append(classify(text))\n",
    "\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(y_pred)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {file_path}: {e}\")\n",
    "\n",
    "# === Evaluation ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "if all_y_true:\n",
    "    acc = accuracy_score(all_y_true, all_y_pred)\n",
    "    prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(f\"  âœ… Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  âœ… Precision: {prec:.4f}\")\n",
    "    print(f\"  âœ… Recall:    {rec:.4f}\")\n",
    "    print(f\"  âœ… F1 Score:  {f1:.4f}\")\n",
    "\n",
    "    # Save metrics (optional)\n",
    "    pd.DataFrame([{\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    }]).to_csv(\"summary_metrics.csv\", index=False)\n",
    "else:\n",
    "    print(\"âš ï¸ No predictions to evaluate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anti Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:30:01.733594Z",
     "iopub.status.busy": "2025-07-14T11:30:01.732906Z",
     "iopub.status.idle": "2025-07-14T11:33:00.407419Z",
     "shell.execute_reply": "2025-07-14T11:33:00.406626Z",
     "shell.execute_reply.started": "2025-07-14T11:30:01.733566Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9771bbcf0974de19f7d3126750eb192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_COVID-19_texts_phi3_Anti-Vacciner.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_phi3_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_HPV_texts_phi3_Anti-Vacciner.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_HPV_texts_phi3_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_Influenza_texts_phi3_Anti-Vacciner.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_phi3_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.4900\n",
      "  âœ… Precision: 0.2450\n",
      "  âœ… Recall:    0.5000\n",
      "  âœ… F1 Score:  0.3289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# === Hugging Face Token ===\n",
    "login(\"\")  # Replace with your token\n",
    "\n",
    "# === Load Phi-3 Model ===\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt Formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            use_cache=False,  # â›” Fix for 'DynamicCache' bug\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === Your Files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts_phi3_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_phi3_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi3_Anti-Vacciner.csv'\n",
    "]\n",
    "\n",
    "# === Evaluate Across Files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    print(f\"\\nðŸ” Loading file: {os.path.basename(file_path)}\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # ðŸ”„ Melt the dataframe so 'label' = column name, 'text' = value\n",
    "        df = pd.melt(df, var_name='label', value_name='text')\n",
    "        df.dropna(inplace=True)\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        df = df.head(100)  # Cap to 100 samples for speed\n",
    "        \n",
    "        y_true = df['label'].tolist()\n",
    "        y_pred = []\n",
    "\n",
    "        for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "            y_pred.append(classify(text))\n",
    "\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(y_pred)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {file_path}: {e}\")\n",
    "\n",
    "# === Evaluation ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "if all_y_true:\n",
    "    acc = accuracy_score(all_y_true, all_y_pred)\n",
    "    prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(f\"  âœ… Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  âœ… Precision: {prec:.4f}\")\n",
    "    print(f\"  âœ… Recall:    {rec:.4f}\")\n",
    "    print(f\"  âœ… F1 Score:  {f1:.4f}\")\n",
    "\n",
    "    # Save metrics (optional)\n",
    "    pd.DataFrame([{\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    }]).to_csv(\"summary_metrics.csv\", index=False)\n",
    "else:\n",
    "    print(\"âš ï¸ No predictions to evaluate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Religious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:40:32.347309Z",
     "iopub.status.busy": "2025-07-14T11:40:32.346620Z",
     "iopub.status.idle": "2025-07-14T11:43:36.891266Z",
     "shell.execute_reply": "2025-07-14T11:43:36.890450Z",
     "shell.execute_reply.started": "2025-07-14T11:40:32.347282Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ad43cd9e5a4d8b8e41eb4ea9a50e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_Influenza_texts_phi_religious_conspiracy.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_phi_religious_conspiracy.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:58<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_HPV_texts_phi_religious_conspiracy.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_HPV_texts_phi_religious_conspiracy.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:58<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_COVID-19_texts_phi_religious_conspiracy (2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_phi_religious_conspiracy (2).csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:57<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.5067\n",
      "  âœ… Precision: 0.2533\n",
      "  âœ… Recall:    0.5000\n",
      "  âœ… F1 Score:  0.3363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# === Hugging Face Token ===\n",
    "login(\"\")  # Replace with your token\n",
    "\n",
    "# === Load Phi-3 Model ===\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt Formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            use_cache=False,  # â›” Fix for 'DynamicCache' bug\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === Your Files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi_religious_conspiracy.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_phi_religious_conspiracy.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts_phi_religious_conspiracy (2).csv'\n",
    "]\n",
    "\n",
    "# === Evaluate Across Files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    print(f\"\\nðŸ” Loading file: {os.path.basename(file_path)}\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # ðŸ”„ Melt the dataframe so 'label' = column name, 'text' = value\n",
    "        df = pd.melt(df, var_name='label', value_name='text')\n",
    "        df.dropna(inplace=True)\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        df = df.head(100)  # Cap to 100 samples for speed\n",
    "        \n",
    "        y_true = df['label'].tolist()\n",
    "        y_pred = []\n",
    "\n",
    "        for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "            y_pred.append(classify(text))\n",
    "\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(y_pred)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {file_path}: {e}\")\n",
    "\n",
    "# === Evaluation ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "if all_y_true:\n",
    "    acc = accuracy_score(all_y_true, all_y_pred)\n",
    "    prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(f\"  âœ… Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  âœ… Precision: {prec:.4f}\")\n",
    "    print(f\"  âœ… Recall:    {rec:.4f}\")\n",
    "    print(f\"  âœ… F1 Score:  {f1:.4f}\")\n",
    "\n",
    "    # Save metrics (optional)\n",
    "    pd.DataFrame([{\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    }]).to_csv(\"summary_metrics.csv\", index=False)\n",
    "else:\n",
    "    print(\"âš ï¸ No predictions to evaluate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fear Monger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:44:39.273739Z",
     "iopub.status.busy": "2025-07-14T11:44:39.273390Z",
     "iopub.status.idle": "2025-07-14T11:46:45.002988Z",
     "shell.execute_reply": "2025-07-14T11:46:45.002131Z",
     "shell.execute_reply.started": "2025-07-14T11:44:39.273680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11159b2b02ac4d229a3196913fac6c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_Influenza_texts_phi_fear_monger.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_phi_fear_monger.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:58<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_HPV_texts_Phi_fear.csv\n",
      "âŒ Error processing /kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_Phi_fear.csv: 'utf-8' codec can't decode bytes in position 137780-137781: invalid continuation byte\n",
      "\n",
      "ðŸ” Loading file: clean_COVID-19_texts__phi3_fear.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts__phi3_fear.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:58<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.5500\n",
      "  âœ… Precision: 0.2750\n",
      "  âœ… Recall:    0.5000\n",
      "  âœ… F1 Score:  0.3548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# === Hugging Face Token ===\n",
    "login(\"\")  # Replace with your token\n",
    "\n",
    "# === Load Phi-3 Model ===\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt Formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            use_cache=False,  # â›” Fix for 'DynamicCache' bug\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === Your Files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi_fear_monger.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_Phi_fear.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts__phi3_fear.csv'\n",
    "]\n",
    "\n",
    "# === Evaluate Across Files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    print(f\"\\nðŸ” Loading file: {os.path.basename(file_path)}\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # ðŸ”„ Melt the dataframe so 'label' = column name, 'text' = value\n",
    "        df = pd.melt(df, var_name='label', value_name='text')\n",
    "        df.dropna(inplace=True)\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        df = df.head(100)  # Cap to 100 samples for speed\n",
    "        \n",
    "        y_true = df['label'].tolist()\n",
    "        y_pred = []\n",
    "\n",
    "        for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "            y_pred.append(classify(text))\n",
    "\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(y_pred)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {file_path}: {e}\")\n",
    "\n",
    "# === Evaluation ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "if all_y_true:\n",
    "    acc = accuracy_score(all_y_true, all_y_pred)\n",
    "    prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(f\"  âœ… Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  âœ… Precision: {prec:.4f}\")\n",
    "    print(f\"  âœ… Recall:    {rec:.4f}\")\n",
    "    print(f\"  âœ… F1 Score:  {f1:.4f}\")\n",
    "\n",
    "    # Save metrics (optional)\n",
    "    pd.DataFrame([{\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    }]).to_csv(\"summary_metrics.csv\", index=False)\n",
    "else:\n",
    "    print(\"âš ï¸ No predictions to evaluate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:51:08.573987Z",
     "iopub.status.busy": "2025-07-14T11:51:08.573268Z",
     "iopub.status.idle": "2025-07-14T11:55:14.290900Z",
     "shell.execute_reply": "2025-07-14T11:55:14.290012Z",
     "shell.execute_reply.started": "2025-07-14T11:51:08.573961Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 11:51:16.946666: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752493876.969777     219 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752493876.976928     219 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0bf286fca94e0eb21c8292e9edde02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_COVID-19_texts_phi_religious_conspiracy (2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_phi_religious_conspiracy (2).csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:57<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_COVID-19_texts_phi3_Misinformation spreader.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_phi3_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_COVID-19_texts_phi3_Anti-Vacciner.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_phi3_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_COVID-19_texts__phi3_fear.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts__phi3_fear.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.5075\n",
      "  âœ… Precision: 0.2537\n",
      "  âœ… Recall:    0.5000\n",
      "  âœ… F1 Score:  0.3367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# === Hugging Face Token ===\n",
    "login(\"\")  # Replace with your token\n",
    "\n",
    "# === Load Phi-3 Model ===\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt Formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            use_cache=False,  # â›” Fix for 'DynamicCache' bug\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === Your Files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts_phi_religious_conspiracy (2).csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts_phi3_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts_phi3_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts__phi3_fear.csv'\n",
    "]\n",
    "\n",
    "# === Evaluate Across Files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    print(f\"\\nðŸ” Loading file: {os.path.basename(file_path)}\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # ðŸ”„ Melt the dataframe so 'label' = column name, 'text' = value\n",
    "        df = pd.melt(df, var_name='label', value_name='text')\n",
    "        df.dropna(inplace=True)\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        df = df.head(100)  # Cap to 100 samples for speed\n",
    "        \n",
    "        y_true = df['label'].tolist()\n",
    "        y_pred = []\n",
    "\n",
    "        for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "            y_pred.append(classify(text))\n",
    "\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(y_pred)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {file_path}: {e}\")\n",
    "\n",
    "# === Evaluation ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "if all_y_true:\n",
    "    acc = accuracy_score(all_y_true, all_y_pred)\n",
    "    prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(f\"  âœ… Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  âœ… Precision: {prec:.4f}\")\n",
    "    print(f\"  âœ… Recall:    {rec:.4f}\")\n",
    "    print(f\"  âœ… F1 Score:  {f1:.4f}\")\n",
    "\n",
    "    # Save metrics (optional)\n",
    "    pd.DataFrame([{\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    }]).to_csv(\"summary_metrics.csv\", index=False)\n",
    "else:\n",
    "    print(\"âš ï¸ No predictions to evaluate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T11:58:41.578382Z",
     "iopub.status.busy": "2025-07-14T11:58:41.577579Z",
     "iopub.status.idle": "2025-07-14T12:01:42.248161Z",
     "shell.execute_reply": "2025-07-14T12:01:42.247314Z",
     "shell.execute_reply.started": "2025-07-14T11:58:41.578343Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4cce65149c4c1c8f85b64b94aabc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_HPV_texts_phi_religious_conspiracy.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_HPV_texts_phi_religious_conspiracy.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:57<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_HPV_texts_phi3_Misinformation spreader.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_HPV_texts_phi3_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_HPV_texts_phi3_Anti-Vacciner.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_HPV_texts_phi3_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_HPV_texts_Phi_fear.csv\n",
      "âŒ Error processing /kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_Phi_fear.csv: 'utf-8' codec can't decode bytes in position 137780-137781: invalid continuation byte\n",
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.4733\n",
      "  âœ… Precision: 0.2367\n",
      "  âœ… Recall:    0.5000\n",
      "  âœ… F1 Score:  0.3213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# === Hugging Face Token ===\n",
    "login(\"\")  # Replace with your token\n",
    "\n",
    "# === Load Phi-3 Model ===\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt Formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            use_cache=False,  # â›” Fix for 'DynamicCache' bug\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === Your Files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_phi_religious_conspiracy.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_phi3_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_phi3_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_Phi_fear.csv'\n",
    "]\n",
    "\n",
    "# === Evaluate Across Files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    print(f\"\\nðŸ” Loading file: {os.path.basename(file_path)}\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # ðŸ”„ Melt the dataframe so 'label' = column name, 'text' = value\n",
    "        df = pd.melt(df, var_name='label', value_name='text')\n",
    "        df.dropna(inplace=True)\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        df = df.head(100)  # Cap to 100 samples for speed\n",
    "        \n",
    "        y_true = df['label'].tolist()\n",
    "        y_pred = []\n",
    "\n",
    "        for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "            y_pred.append(classify(text))\n",
    "\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(y_pred)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {file_path}: {e}\")\n",
    "\n",
    "# === Evaluation ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "if all_y_true:\n",
    "    acc = accuracy_score(all_y_true, all_y_pred)\n",
    "    prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(f\"  âœ… Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  âœ… Precision: {prec:.4f}\")\n",
    "    print(f\"  âœ… Recall:    {rec:.4f}\")\n",
    "    print(f\"  âœ… F1 Score:  {f1:.4f}\")\n",
    "\n",
    "    # Save metrics (optional)\n",
    "    pd.DataFrame([{\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    }]).to_csv(\"summary_metrics.csv\", index=False)\n",
    "else:\n",
    "    print(\"âš ï¸ No predictions to evaluate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T12:02:44.488119Z",
     "iopub.status.busy": "2025-07-14T12:02:44.487506Z",
     "iopub.status.idle": "2025-07-14T12:06:40.333730Z",
     "shell.execute_reply": "2025-07-14T12:06:40.332734Z",
     "shell.execute_reply.started": "2025-07-14T12:02:44.488094Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c24dc43efd54c47b7a0119881b934cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_Influenza_texts_phi_religious_conspiracy.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_phi_religious_conspiracy.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_Influenza_texts_phi_fear_monger.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_phi_fear_monger.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_Influenza_texts_phi3_Misinformation spreader.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_phi3_Misinformation spreader.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_Influenza_texts_phi3_Anti-Vacciner.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_phi3_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:55<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.5075\n",
      "  âœ… Precision: 0.2537\n",
      "  âœ… Recall:    0.5000\n",
      "  âœ… F1 Score:  0.3367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# === Hugging Face Token ===\n",
    "login(\"\")  # Replace with your token\n",
    "\n",
    "# === Load Phi-3 Model ===\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt Formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            use_cache=False,  # â›” Fix for 'DynamicCache' bug\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === Your Files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi_religious_conspiracy.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi_fear_monger.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi3_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi3_Anti-Vacciner.csv'\n",
    "]\n",
    "\n",
    "# === Evaluate Across Files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    print(f\"\\nðŸ” Loading file: {os.path.basename(file_path)}\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # ðŸ”„ Melt the dataframe so 'label' = column name, 'text' = value\n",
    "        df = pd.melt(df, var_name='label', value_name='text')\n",
    "        df.dropna(inplace=True)\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        df = df.head(100)  # Cap to 100 samples for speed\n",
    "        \n",
    "        y_true = df['label'].tolist()\n",
    "        y_pred = []\n",
    "\n",
    "        for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "            y_pred.append(classify(text))\n",
    "\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(y_pred)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {file_path}: {e}\")\n",
    "\n",
    "# === Evaluation ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "if all_y_true:\n",
    "    acc = accuracy_score(all_y_true, all_y_pred)\n",
    "    prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(f\"  âœ… Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  âœ… Precision: {prec:.4f}\")\n",
    "    print(f\"  âœ… Recall:    {rec:.4f}\")\n",
    "    print(f\"  âœ… F1 Score:  {f1:.4f}\")\n",
    "\n",
    "    # Save metrics (optional)\n",
    "    pd.DataFrame([{\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    }]).to_csv(\"summary_metrics.csv\", index=False)\n",
    "else:\n",
    "    print(\"âš ï¸ No predictions to evaluate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T12:15:20.083956Z",
     "iopub.status.busy": "2025-07-14T12:15:20.083657Z",
     "iopub.status.idle": "2025-07-14T12:25:01.883843Z",
     "shell.execute_reply": "2025-07-14T12:25:01.882873Z",
     "shell.execute_reply.started": "2025-07-14T12:15:20.083936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 12:15:28.362956: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752495328.386569     309 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752495328.393594     309 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534bdcf45a0147839faa62d95f066a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_Influenza_texts_phi_fear_monger.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_phi_fear_monger.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_HPV_texts_Phi_fear.csv\n",
      "âŒ Error processing /kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_Phi_fear.csv: 'utf-8' codec can't decode bytes in position 137780-137781: invalid continuation byte\n",
      "\n",
      "ðŸ” Loading file: clean_COVID-19_texts__phi3_fear.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts__phi3_fear.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_Influenza_texts_phi_fear_monger.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_phi_fear_monger.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:55<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_HPV_texts_Phi_fear.csv\n",
      "âŒ Error processing /kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_Phi_fear.csv: 'utf-8' codec can't decode bytes in position 137780-137781: invalid continuation byte\n",
      "\n",
      "ðŸ” Loading file: clean_COVID-19_texts__phi3_fear.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts__phi3_fear.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_Influenza_texts_phi_religious_conspiracy.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_phi_religious_conspiracy.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_HPV_texts_phi_religious_conspiracy.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_HPV_texts_phi_religious_conspiracy.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_COVID-19_texts_phi_religious_conspiracy (2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_phi_religious_conspiracy (2).csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_COVID-19_texts_phi3_Anti-Vacciner.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_phi3_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_HPV_texts_phi3_Anti-Vacciner.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_HPV_texts_phi3_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:56<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loading file: clean_Influenza_texts_phi3_Anti-Vacciner.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_phi3_Anti-Vacciner.csv: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:55<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š === Overall Evaluation Across All Files ===\n",
      "  âœ… Accuracy:  0.4950\n",
      "  âœ… Precision: 0.2475\n",
      "  âœ… Recall:    0.5000\n",
      "  âœ… F1 Score:  0.3311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# === Hugging Face Token ===\n",
    "login(\"\")  # Replace with your token\n",
    "\n",
    "# === Load Phi-3 Model ===\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Prompt Formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"### Instruction:\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "### Text:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# === Inference ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            use_cache=False,  # â›” Fix for 'DynamicCache' bug\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Misinformation\" in decoded:\n",
    "        return \"Misinformation\"\n",
    "    elif \"Neutral\" in decoded:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === Your Files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi_fear_monger.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_Phi_fear.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts__phi3_fear.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi_fear_monger.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_Phi_fear.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts__phi3_fear.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi_religious_conspiracy.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_phi_religious_conspiracy.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts_phi_religious_conspiracy (2).csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/COVID-19/clean_COVID-19_texts_phi3_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/HPV/clean_HPV_texts_phi3_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard-data/VaxGaurd-Dataset-roles (New)/PHI3/INFLUENZA/clean_Influenza_texts_phi3_Anti-Vacciner.csv'\n",
    "]\n",
    "\n",
    "# === Evaluate Across Files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    print(f\"\\nðŸ” Loading file: {os.path.basename(file_path)}\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # ðŸ”„ Melt the dataframe so 'label' = column name, 'text' = value\n",
    "        df = pd.melt(df, var_name='label', value_name='text')\n",
    "        df.dropna(inplace=True)\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        df = df.head(100)  # Cap to 100 samples for speed\n",
    "        \n",
    "        y_true = df['label'].tolist()\n",
    "        y_pred = []\n",
    "\n",
    "        for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "            y_pred.append(classify(text))\n",
    "\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(y_pred)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {file_path}: {e}\")\n",
    "\n",
    "# === Evaluation ===\n",
    "print(\"\\nðŸ“Š === Overall Evaluation Across All Files ===\")\n",
    "if all_y_true:\n",
    "    acc = accuracy_score(all_y_true, all_y_pred)\n",
    "    prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(f\"  âœ… Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  âœ… Precision: {prec:.4f}\")\n",
    "    print(f\"  âœ… Recall:    {rec:.4f}\")\n",
    "    print(f\"  âœ… F1 Score:  {f1:.4f}\")\n",
    "\n",
    "    # Save metrics (optional)\n",
    "    pd.DataFrame([{\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    }]).to_csv(\"summary_metrics.csv\", index=False)\n",
    "else:\n",
    "    print(\"âš ï¸ No predictions to evaluate.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7863655,
     "sourceId": 12465134,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
