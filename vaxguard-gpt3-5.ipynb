{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-15T07:54:31.131327Z",
     "iopub.status.busy": "2025-07-15T07:54:31.130665Z",
     "iopub.status.idle": "2025-07-15T07:54:31.513987Z",
     "shell.execute_reply": "2025-07-15T07:54:31.513380Z",
     "shell.execute_reply.started": "2025-07-15T07:54:31.131300Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/HPV/clean_HPV_texts_phi3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/HPV/clean_HPV_texts_Phi_fear.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/HPV/clean_HPV_texts_phi3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/HPV/clean_HPV_texts_phi_religious_conspiracy.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/COVID-19/clean_COVID-19_texts_phi3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/COVID-19/clean_COVID-19_texts_phi3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/COVID-19/clean_COVID-19_texts__phi3_fear.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/COVID-19/clean_COVID-19_texts_phi_religious_conspiracy (2).csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/INFLUENZA/clean_Influenza_texts_phi_fear_monger.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/INFLUENZA/clean_Influenza_texts_phi3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/INFLUENZA/clean_Influenza_texts_phi3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/PHI3/INFLUENZA/clean_Influenza_texts_phi_religious_conspiracy.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/HPV/clean_HPV_texts_GPT-4o_fear mongerer.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/COVID-19/clean_COVID-19_texts_GPT-4o_fear mongerer.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_fear mongerer.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-4o/Influenza/clean_Influenza_texts_GPT-4o_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_fear mongerer.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_fear mongerer.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_fear mongerer.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_religious Conspiracy theorist.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/HPV/clean_HPV_texts_llama_religious.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/HPV/clean_HPV_texts_llama3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/HPV/clean_HPV_texts_llama_fear_monger.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/HPV/clean_HPV_texts_llama3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/COVID-19/clean_COVID-19_texts_llama_religious.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/COVID-19/clean_COVID-19_texts_llama3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/COVID-19/clean_COVID-19_texts_llama_fear_monger.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/COVID-19/clean_COVID-19_texts_llama3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/INFLUENZA/clean_Influenza_texts_llama_reilgious.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/INFLUENZA/clean_Influenza_texts_llama3_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/INFLUENZA/clean_Influenza_texts_llama3_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/INFLUENZA/clean_Influenza_texts_llama_fear_monger.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_fear.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_religious.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/HPV/clean_HPV_texts_mistral_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_fear.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_Misinformation spreader.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/COVID-19/clean_COVID-19_texts_mistral_religious.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_religious.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_fear.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_Anti-Vacciner.csv\n",
      "/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Mistral/INFLUENZA/clean_Influenza_texts_mistral_Misinformation spreader.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T08:03:13.213996Z",
     "iopub.status.busy": "2025-07-15T08:03:13.213511Z",
     "iopub.status.idle": "2025-07-15T08:03:21.018573Z",
     "shell.execute_reply": "2025-07-15T08:03:21.017618Z",
     "shell.execute_reply.started": "2025-07-15T08:03:13.213972Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n",
      "Collecting openai\n",
      "  Downloading openai-1.95.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Downloading openai-1.95.1-py3-none-any.whl (755 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.91.0\n",
      "    Uninstalling openai-1.91.0:\n",
      "      Successfully uninstalled openai-1.91.0\n",
      "Successfully installed openai-1.95.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers accelerate datasets evaluate -q\n",
    "#!pip install huggingface_hub -q\n",
    "!pip install --upgrade openai\n",
    "!pip install --upgrade transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-15T08:04:08.578Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misinformation Spreader\n",
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T08:26:16.755226Z",
     "iopub.status.busy": "2025-07-15T08:26:16.754907Z",
     "iopub.status.idle": "2025-07-15T08:28:11.624116Z",
     "shell.execute_reply": "2025-07-15T08:28:11.623345Z",
     "shell.execute_reply.started": "2025-07-15T08:26:16.755203Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_llama3_Misinformation spreader.csv: 100%|██████████| 100/100 [00:42<00:00,  2.38it/s]\n",
      "Classifying clean_HPV_texts_llama3_Misinformation spreader.csv: 100%|██████████| 100/100 [00:36<00:00,  2.70it/s]\n",
      "Classifying clean_COVID-19_texts_llama3_Misinformation spreader.csv: 100%|██████████| 100/100 [00:35<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.9967\n",
      "  ✅ Precision: 0.9968\n",
      "  ✅ Recall:    0.9965\n",
      "  ✅ F1 Score:  0.9967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/INFLUENZA/clean_Influenza_texts_llama3_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/HPV/clean_HPV_texts_llama3_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/COVID-19/clean_COVID-19_texts_llama3_Misinformation spreader.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Religious Consoiracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T08:33:46.992407Z",
     "iopub.status.busy": "2025-07-15T08:33:46.992067Z",
     "iopub.status.idle": "2025-07-15T08:36:28.174808Z",
     "shell.execute_reply": "2025-07-15T08:36:28.174051Z",
     "shell.execute_reply.started": "2025-07-15T08:33:46.992388Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_GPT-3.5_religious Conspiracy theorist.csv: 100%|██████████| 100/100 [00:37<00:00,  2.70it/s]\n",
      "Classifying clean_HPV_texts_GPT-3.5_religious Conspiracy theorist.csv: 100%|██████████| 100/100 [00:41<00:00,  2.40it/s]\n",
      "Classifying clean_Influenza_texts_GPT-3.5_religious Conspiracy theorist.csv: 100%|██████████| 100/100 [01:22<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.7667\n",
      "  ✅ Precision: 0.5405\n",
      "  ✅ Recall:    0.6667\n",
      "  ✅ F1 Score:  0.5889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_religious Conspiracy theorist.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fear Monger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T08:43:47.422141Z",
     "iopub.status.busy": "2025-07-15T08:43:47.421424Z",
     "iopub.status.idle": "2025-07-15T08:45:49.898064Z",
     "shell.execute_reply": "2025-07-15T08:45:49.897232Z",
     "shell.execute_reply.started": "2025-07-15T08:43:47.422117Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_GPT-3.5_fear mongerer.csv: 100%|██████████| 100/100 [00:43<00:00,  2.31it/s]\n",
      "Classifying clean_HPV_texts_GPT-3.5_fear mongerer.csv: 100%|██████████| 100/100 [00:38<00:00,  2.62it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-3.5_fear mongerer.csv: 100%|██████████| 100/100 [00:40<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.9067\n",
      "  ✅ Precision: 0.6118\n",
      "  ✅ Recall:    0.6667\n",
      "  ✅ F1 Score:  0.6368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_fear mongerer.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anti-vacciner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T08:47:29.293827Z",
     "iopub.status.busy": "2025-07-15T08:47:29.293238Z",
     "iopub.status.idle": "2025-07-15T08:49:19.477053Z",
     "shell.execute_reply": "2025-07-15T08:49:19.476214Z",
     "shell.execute_reply.started": "2025-07-15T08:47:29.293799Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_GPT-3.5_Anti-Vacciner.csv: 100%|██████████| 100/100 [00:37<00:00,  2.64it/s]\n",
      "Classifying clean_HPV_texts_GPT-3.5_Anti-Vacciner.csv: 100%|██████████| 100/100 [00:35<00:00,  2.82it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-3.5_Anti-Vacciner.csv: 100%|██████████| 100/100 [00:36<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.8967\n",
      "  ✅ Precision: 0.6033\n",
      "  ✅ Recall:    0.6667\n",
      "  ✅ F1 Score:  0.6316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_146/1556431855.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  ✅ Recall:    {overall_rec:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  ✅ F1 Score:  {overall_f1:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'D' is not defined"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_Anti-Vacciner.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T08:51:23.411592Z",
     "iopub.status.busy": "2025-07-15T08:51:23.410955Z",
     "iopub.status.idle": "2025-07-15T08:53:58.121671Z",
     "shell.execute_reply": "2025-07-15T08:53:58.120930Z",
     "shell.execute_reply.started": "2025-07-15T08:51:23.411568Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_COVID-19_texts_GPT-3.5_religious Conspiracy theorist.csv: 100%|██████████| 100/100 [00:36<00:00,  2.76it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-3.5_fear mongerer.csv: 100%|██████████| 100/100 [00:41<00:00,  2.40it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-3.5_Misinformation spreader.csv: 100%|██████████| 100/100 [00:38<00:00,  2.58it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-3.5_Anti-Vacciner.csv: 100%|██████████| 100/100 [00:37<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.6425\n",
      "  ✅ Precision: 0.4901\n",
      "  ✅ Recall:    0.6667\n",
      "  ✅ F1 Score:  0.5466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_Anti-Vacciner.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T08:54:04.669742Z",
     "iopub.status.busy": "2025-07-15T08:54:04.669159Z",
     "iopub.status.idle": "2025-07-15T08:56:45.032644Z",
     "shell.execute_reply": "2025-07-15T08:56:45.031904Z",
     "shell.execute_reply.started": "2025-07-15T08:54:04.669715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_HPV_texts_GPT-3.5_religious Conspiracy theorist.csv: 100%|██████████| 100/100 [00:36<00:00,  2.74it/s]\n",
      "Classifying clean_HPV_texts_GPT-3.5_fear mongerer.csv: 100%|██████████| 100/100 [00:42<00:00,  2.34it/s]\n",
      "Classifying clean_HPV_texts_GPT-3.5_Misinformation spreader.csv: 100%|██████████| 100/100 [00:36<00:00,  2.73it/s]\n",
      "Classifying clean_HPV_texts_GPT-3.5_Anti-Vacciner.csv: 100%|██████████| 100/100 [00:44<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.9125\n",
      "  ✅ Precision: 0.6095\n",
      "  ✅ Recall:    0.6667\n",
      "  ✅ F1 Score:  0.6354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_Anti-Vacciner.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFLUENZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T08:56:57.734983Z",
     "iopub.status.busy": "2025-07-15T08:56:57.734283Z",
     "iopub.status.idle": "2025-07-15T08:59:28.727199Z",
     "shell.execute_reply": "2025-07-15T08:59:28.726506Z",
     "shell.execute_reply.started": "2025-07-15T08:56:57.734957Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_GPT-3.5_religious Conspiracy theorist.csv: 100%|██████████| 100/100 [00:36<00:00,  2.76it/s]\n",
      "Classifying clean_Influenza_texts_GPT-3.5_fear mongerer.csv: 100%|██████████| 100/100 [00:37<00:00,  2.65it/s]\n",
      "Classifying clean_Influenza_texts_GPT-3.5_Misinformation spreader.csv: 100%|██████████| 100/100 [00:35<00:00,  2.79it/s]\n",
      "Classifying clean_Influenza_texts_GPT-3.5_Anti-Vacciner.csv: 100%|██████████| 100/100 [00:41<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  1.0000\n",
      "  ✅ Precision: 1.0000\n",
      "  ✅ Recall:    1.0000\n",
      "  ✅ F1 Score:  1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key =\n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_Anti-Vacciner.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T09:21:46.105250Z",
     "iopub.status.busy": "2025-07-15T09:21:46.104955Z",
     "iopub.status.idle": "2025-07-15T09:39:22.112551Z",
     "shell.execute_reply": "2025-07-15T09:39:22.111685Z",
     "shell.execute_reply.started": "2025-07-15T09:21:46.105230Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying clean_Influenza_texts_GPT-3.5_Anti-Vacciner.csv: 100%|██████████| 100/100 [00:39<00:00,  2.52it/s]\n",
      "Classifying clean_HPV_texts_GPT-3.5_Anti-Vacciner.csv: 100%|██████████| 100/100 [00:37<00:00,  2.64it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-3.5_Anti-Vacciner.csv: 100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n",
      "Classifying clean_Influenza_texts_GPT-3.5_fear mongerer.csv: 100%|██████████| 100/100 [00:41<00:00,  2.40it/s]\n",
      "Classifying clean_HPV_texts_GPT-3.5_fear mongerer.csv: 100%|██████████| 100/100 [00:33<00:00,  2.98it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-3.5_fear mongerer.csv: 100%|██████████| 100/100 [00:36<00:00,  2.76it/s]\n",
      "Classifying clean_COVID-19_texts_GPT-3.5_religious Conspiracy theorist.csv: 100%|██████████| 100/100 [10:36<00:00,  6.36s/it]  \n",
      "Classifying clean_HPV_texts_GPT-3.5_religious Conspiracy theorist.csv: 100%|██████████| 100/100 [00:44<00:00,  2.23it/s]\n",
      "Classifying clean_Influenza_texts_GPT-3.5_religious Conspiracy theorist.csv: 100%|██████████| 100/100 [00:38<00:00,  2.62it/s]\n",
      "Classifying clean_Influenza_texts_llama3_Misinformation spreader.csv: 100%|██████████| 100/100 [00:36<00:00,  2.74it/s]\n",
      "Classifying clean_HPV_texts_llama3_Misinformation spreader.csv: 100%|██████████| 100/100 [00:37<00:00,  2.65it/s]\n",
      "Classifying clean_COVID-19_texts_llama3_Misinformation spreader.csv: 100%|██████████| 100/100 [00:34<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Overall Evaluation Across All Files ===\n",
      "  ✅ Accuracy:  0.8950\n",
      "  ✅ Precision: 0.6045\n",
      "  ✅ Recall:    0.6655\n",
      "  ✅ F1 Score:  0.6320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Set OpenAI API key ===\n",
    "openai.api_key = \n",
    "# === Create OpenAI client ===\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "# === Prompt formatting ===\n",
    "def format_prompt(text):\n",
    "    return f\"\"\"You are an expert fact-checking assistant.\n",
    "\n",
    "Classify the following text as either Neutral or Misinformation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Respond with only one word: Neutral or Misinformation.\"\"\"\n",
    "\n",
    "# === Inference function ===\n",
    "def classify(text):\n",
    "    prompt = format_prompt(text)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        if \"Misinformation\" in reply:\n",
    "            return \"Misinformation\"\n",
    "        elif \"Neutral\" in reply:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# === List your CSV files ===\n",
    "csv_files = [\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_Anti-Vacciner.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_fear mongerer.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/COVID-19/clean_COVID-19_texts_GPT-3.5_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/HPV/clean_HPV_texts_GPT-3.5_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/GPT-3.5/INFLUENZA/clean_Influenza_texts_GPT-3.5_religious Conspiracy theorist.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/INFLUENZA/clean_Influenza_texts_llama3_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/HPV/clean_HPV_texts_llama3_Misinformation spreader.csv',\n",
    "    '/kaggle/input/vaxguard/VaxGaurd-Dataset-roles/Llama 3/COVID-19/clean_COVID-19_texts_llama3_Misinformation spreader.csv'\n",
    "]\n",
    "\n",
    "# === Collect predictions from all files ===\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df, var_name='label', value_name='text')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df = df.head(100)  # Optional: limit to 100 rows\n",
    "\n",
    "    y_true = df['label'].tolist()\n",
    "    y_pred = []\n",
    "\n",
    "    for text in tqdm(df['text'], desc=f\"Classifying {os.path.basename(file_path)}\"):\n",
    "        y_pred.append(classify(text))\n",
    "\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# === Overall Evaluation Metrics ===\n",
    "print(\"\\n📊 === Overall Evaluation Across All Files ===\")\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"  ✅ Accuracy:  {overall_acc:.4f}\")\n",
    "print(f\"  ✅ Precision: {overall_prec:.4f}\")\n",
    "print(f\"  ✅ Recall:    {overall_rec:.4f}\")\n",
    "print(f\"  ✅ F1 Score:  {overall_f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7859405,
     "sourceId": 12459014,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
